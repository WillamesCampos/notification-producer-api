<div align="center">
  <img width="250" height="250" alt="Flix API Logo" src="https://github.com/user-attachments/assets/5460ba01-9b90-4958-9c70-2b2bf8393470" />
" />
</div>

# ğŸ”” Notification System

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.122+-green.svg)](https://fastapi.tiangolo.com/)
[![Kafka](https://img.shields.io/badge/Kafka-7.5.0-orange.svg)](https://kafka.apache.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

Sistema de notificaÃ§Ãµes distribuÃ­do baseado em arquitetura de microserviÃ§os e event-driven, utilizando Apache Kafka como message broker. O sistema permite a publicaÃ§Ã£o e consumo de eventos de notificaÃ§Ã£o de forma assÃ­ncrona e escalÃ¡vel.

---

## ğŸ“‹ Ãndice

- [Sobre o Projeto](#-sobre-o-projeto)
- [Arquitetura](#-arquitetura)
- [Tecnologias](#-tecnologias)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o e ExecuÃ§Ã£o](#-instalaÃ§Ã£o-e-execuÃ§Ã£o)
- [API Endpoints](#-api-endpoints)
- [Formato dos Eventos](#-formato-dos-eventos)
- [Aprendizado](#-aprendizado)
- [VariÃ¡veis de Ambiente](#-variÃ¡veis-de-ambiente)
- [Comandos Ãšteis](#-comandos-Ãºteis)
- [Roadmap](#-roadmap)
- [Troubleshooting](#-troubleshooting)
- [Contribuindo](#-contribuindo)
- [LicenÃ§a](#-licenÃ§a)

---

## ğŸ¯ Sobre o Projeto

O **Notification System** Ã© uma soluÃ§Ã£o moderna para gerenciamento de notificaÃ§Ãµes em tempo real, construÃ­da com arquitetura de microserviÃ§os e padrÃµes event-driven. O sistema foi projetado para ser:

- âš¡ **AssÃ­ncrono**: Processamento nÃ£o-bloqueante de eventos
- ğŸ”„ **EscalÃ¡vel**: Arquitetura distribuÃ­da com Kafka
- ğŸ›¡ï¸ **Resiliente**: Tolerante a falhas com retry automÃ¡tico
- ğŸš€ **PerformÃ¡tico**: FastAPI com suporte nativo a async/await
- ğŸ“¦ **Containerizado**: Deploy simplificado com Docker Compose

---

## ğŸ—ï¸ Arquitetura

### VisÃ£o Geral

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente HTTP  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ HTTP REST
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  notification-producer-api          â”‚
â”‚  (FastAPI - Porta 8001)            â”‚
â”‚  - Recebe requisiÃ§Ãµes HTTP          â”‚
â”‚  - Valida payloads                  â”‚
â”‚  - Publica eventos no Kafka         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ Eventos JSON
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Apache Kafka                       â”‚
â”‚  (Porta 9092/9093)                  â”‚
â”‚  Topic: notifications               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ Consome eventos
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  notification-service (FUTURO)      â”‚
â”‚  - Consome eventos do Kafka         â”‚
â”‚  - Processa notificaÃ§Ãµes            â”‚
â”‚  - Persiste no MongoDB              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ Dados persistidos
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MongoDB                            â”‚
â”‚  (Porta 27017)                      â”‚
â”‚  Database: notifications_db         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Principais

#### 1. **notification-producer-api** ğŸš€
- **Tecnologia**: Python 3.12 + FastAPI
- **Porta**: 8001
- **Responsabilidade**: ExpÃµe API REST para receber e publicar eventos no Kafka
- **DependÃªncias principais**: FastAPI, Uvicorn, aiokafka, Pydantic

#### 2. **Apache Kafka** ğŸ“¨
- **VersÃ£o**: 7.5.0 (Confluent Platform)
- **Portas**: 9092 (interno), 9093 (host)
- **Responsabilidade**: Gerenciar filas de mensagens e distribuir eventos entre serviÃ§os
- **TÃ³picos**: `notifications`

#### 3. **Apache Zookeeper** ğŸ—‚ï¸
- **VersÃ£o**: 7.5.0 (Confluent Platform)
- **Porta**: 2181
- **Responsabilidade**: Gerenciar metadados e coordenaÃ§Ã£o do cluster Kafka

#### 4. **MongoDB** ğŸƒ
- **VersÃ£o**: Latest
- **Porta**: 27017
- **Responsabilidade**: Armazenar notificaÃ§Ãµes processadas
- **Database**: `notifications_db`
- **Credenciais**: `root` / `password`

---

## ğŸ› ï¸ Tecnologias

### Backend
- **Python 3.12** - Linguagem de programaÃ§Ã£o
- **FastAPI** - Framework web assÃ­ncrono moderno
- **Uvicorn** - Servidor ASGI de alta performance
- **aiokafka** - Cliente Kafka assÃ­ncrono para Python
- **Pydantic** - ValidaÃ§Ã£o de dados e configuraÃ§Ãµes

### Infraestrutura
- **Docker & Docker Compose** - ContainerizaÃ§Ã£o e orquestraÃ§Ã£o
- **Apache Kafka** - Message broker distribuÃ­do
- **Apache Zookeeper** - CoordenaÃ§Ã£o de serviÃ§os distribuÃ­dos
- **MongoDB** - Banco de dados NoSQL

### Ferramentas
- **uv** - Gerenciador de pacotes Python moderno e rÃ¡pido

---

## ğŸ“ Estrutura do Projeto

```
notification-producer-api/
â”œâ”€â”€ docker-compose.yaml              # OrquestraÃ§Ã£o de todos os serviÃ§os
â”œâ”€â”€ README.md                        # Este arquivo
â”‚
â””â”€â”€ notification-system/
    â””â”€â”€ services/
        â””â”€â”€ notification-producer-api/
            â”œâ”€â”€ Dockerfile           # Imagem Docker do serviÃ§o
            â”œâ”€â”€ Makefile             # Comandos auxiliares
            â”œâ”€â”€ pyproject.toml       # ConfiguraÃ§Ã£o do projeto Python
            â”œâ”€â”€ uv.lock              # Lock file das dependÃªncias
            â”œâ”€â”€ README.md            # DocumentaÃ§Ã£o especÃ­fica do serviÃ§o
            â”‚
            â””â”€â”€ src/
                â””â”€â”€ notification_producer_api/
                    â”œâ”€â”€ __init__.py
                    â”œâ”€â”€ main.py              # AplicaÃ§Ã£o FastAPI principal
                    â”œâ”€â”€ config.py            # ConfiguraÃ§Ãµes e settings
                    â”‚
                    â””â”€â”€ infrastructure/
                        â”œâ”€â”€ __init__.py
                        â””â”€â”€ kafka_producer.py  # Cliente Kafka Producer
```

---

## ğŸ“¦ PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de ter instalado:

- **Docker** 20.10+ ([InstalaÃ§Ã£o](https://docs.docker.com/get-docker/))
- **Docker Compose** 2.0+ ([InstalaÃ§Ã£o](https://docs.docker.com/compose/install/))
- **Python 3.12+** (opcional, para desenvolvimento local)
- **uv** (opcional, para desenvolvimento local) ([InstalaÃ§Ã£o](https://github.com/astral-sh/uv))

---

## ğŸš€ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone <url-do-repositorio>
cd notification-producer-api
```

### 2. Suba todos os serviÃ§os com Docker Compose

```bash
docker-compose up --build
```

Este comando irÃ¡:
- âœ… Construir a imagem do `notification-producer-api`
- âœ… Iniciar o Zookeeper
- âœ… Iniciar o Kafka
- âœ… Iniciar o MongoDB
- âœ… Iniciar a API na porta 8001

### 3. Verifique se os serviÃ§os estÃ£o rodando

Aguarde aproximadamente 30-60 segundos para todos os serviÃ§os inicializarem completamente. VocÃª pode verificar os logs:

```bash
docker-compose logs -f
```

### 4. Teste o Health Check

```bash
curl http://localhost:8001/health
```

**Resposta esperada:**
```json
{
  "status": "ok",
  "service": "notification-producer-api"
}
```

### 5. Teste o endpoint raiz

```bash
curl http://localhost:8001/
```

**Resposta esperada:**
```json
{
  "message": "Notification Producer API is running"
}
```

---

## ğŸ“¡ API Endpoints

**Base URL**: `http://localhost:8001`

### `GET /`
Endpoint raiz que retorna uma mensagem de boas-vindas.

**Exemplo de requisiÃ§Ã£o:**
```bash
curl http://localhost:8001/
```

**Resposta:**
```json
{
  "message": "Notification Producer API is running"
}
```

---

### `GET /health`
Health check do serviÃ§o. Ãštil para monitoramento e verificaÃ§Ã£o de status.

**Exemplo de requisiÃ§Ã£o:**
```bash
curl http://localhost:8001/health
```

**Resposta:**
```json
{
  "status": "ok",
  "service": "notification-producer-api"
}
```

**Status Codes:**
- `200 OK` - ServiÃ§o estÃ¡ funcionando corretamente

---

### `POST /events` ğŸš§
*Endpoint em desenvolvimento*

Publica um evento no tÃ³pico Kafka `notifications`.

**Exemplo de requisiÃ§Ã£o:**
```bash
curl -X POST http://localhost:8001/events \
  -H "Content-Type: application/json" \
  -d '{
    "event_type": "task.created",
    "user_id": "user-123",
    "payload": {
      "task_title": "Comprar leite",
      "priority": "high"
    }
  }'
```

**Resposta esperada:**
```json
{
  "status": "event published",
  "event_id": "550e8400-e29b-41d4-a716-446655440000",
  "event_type": "task.created"
}
```

---

## ğŸ“¨ Formato dos Eventos

Os eventos publicados no Kafka seguem o seguinte schema JSON:

```json
{
  "event_id": "550e8400-e29b-41d4-a716-446655440000",
  "event_type": "task.created",
  "user_id": "user-123",
  "timestamp": "2024-01-15T10:30:00Z",
  "payload": {
    "task_title": "Comprar leite",
    "priority": "high",
    "due_date": "2024-01-20"
  }
}
```

### Campos ObrigatÃ³rios

- **`event_id`** (string, UUID v4): Identificador Ãºnico do evento
- **`event_type`** (string): Tipo do evento (ex: `task.created`, `comment.added`, `user.updated`)
- **`user_id`** (string): ID do usuÃ¡rio relacionado ao evento
- **`timestamp`** (string, ISO 8601): Data e hora do evento em formato UTC
- **`payload`** (object): Dados especÃ­ficos do evento (estrutura variÃ¡vel)

### Tipos de Eventos Sugeridos

- `task.created` - Nova tarefa criada
- `task.updated` - Tarefa atualizada
- `task.completed` - Tarefa completada
- `comment.added` - ComentÃ¡rio adicionado
- `user.mentioned` - UsuÃ¡rio mencionado
- `notification.sent` - NotificaÃ§Ã£o enviada

---

## ğŸ“š Aprendizado

Esta seÃ§Ã£o documenta os conceitos e padrÃµes implementados no projeto, Ãºteis para entender como o sistema funciona e para referÃªncia futura.

### Kafka Producer

#### Como conectar ao Kafka de dentro do FastAPI

O Kafka Producer Ã© inicializado usando o **lifespan** do FastAPI, garantindo que a conexÃ£o seja estabelecida na inicializaÃ§Ã£o da aplicaÃ§Ã£o e fechada corretamente no shutdown.

**ImplementaÃ§Ã£o:**

```python
from contextlib import asynccontextmanager
from aiokafka import AIOKafkaProducer

_producer: Optional[AIOKafkaProducer] = None

async def init_kafka_producer() -> AIOKafkaProducer:
    global _producer
    _producer = AIOKafkaProducer(
        bootstrap_servers=settings.kafka_bootstrap_servers,
        value_serializer=lambda v: json.dumps(v).encode("utf-8"),
    )
    await _producer.start()
    return _producer

@asynccontextmanager
async def lifespan(app: FastAPI):
    await init_kafka_producer()  # Startup
    yield
    await close_kafka_producer()  # Shutdown

app = FastAPI(lifespan=lifespan)
```

**Pontos importantes:**
- Usa `aiokafka` para operaÃ§Ãµes assÃ­ncronas nÃ£o-bloqueantes
- `value_serializer` converte automaticamente dicts para JSON bytes
- Retry logic implementado para aguardar Kafka estar pronto
- ConexÃ£o global (`_producer`) reutilizada em todas as requisiÃ§Ãµes

#### Como publicar eventos em um tÃ³pico

A publicaÃ§Ã£o de eventos Ã© feita de forma assÃ­ncrona usando `send_and_wait`, que garante que a mensagem foi commitada no Kafka antes de retornar.

**ImplementaÃ§Ã£o:**

```python
async def publish_event(topic: str, event: dict) -> None:
    if _producer is None:
        raise RuntimeError("Kafka producer not initialized")
    
    record_metadata = await _producer.send_and_wait(
        topic=topic,
        value=event  # value_serializer serializa automaticamente
    )
    # record_metadata contÃ©m: partition, offset, timestamp
```

**CaracterÃ­sticas:**
- `send_and_wait` garante que a mensagem foi persistida (acks=all)
- Retorna `RecordMetadata` com informaÃ§Ãµes de partiÃ§Ã£o e offset
- Tratamento de erros com logging estruturado

### TÃ³pico (Topic)

#### O que Ã© um TÃ³pico?

Um **tÃ³pico** Ã© um canal lÃ³gico onde eventos sÃ£o publicados e consumidos. Ã‰ similar a uma fila ou categoria de mensagens.

**No nosso caso:**
- **Nome do tÃ³pico**: `notifications`
- **PartiÃ§Ãµes**: 1 (configurÃ¡vel)
- **ReplicaÃ§Ã£o**: 1 (para desenvolvimento)

**CaracterÃ­sticas:**
- TÃ³picos sÃ£o criados automaticamente na primeira publicaÃ§Ã£o (se `auto.create.topics.enable=true`)
- Mensagens sÃ£o ordenadas dentro de cada partiÃ§Ã£o
- MÃºltiplos consumidores podem ler do mesmo tÃ³pico (consumer groups)

**Comandos Ãºteis:**
```bash
# Listar tÃ³picos
docker exec -it kafka kafka-topics --bootstrap-server kafka:9092 --list

# Descrever tÃ³pico
docker exec -it kafka kafka-topics --bootstrap-server kafka:9092 --describe --topic notifications

# Verificar offsets (quantidade de mensagens)
docker exec -it kafka kafka-run-class kafka.tools.GetOffsetShell --broker-list kafka:9092 --topic notifications
```

### Evento

#### Estrutura de um Evento

Todos os eventos publicados no Kafka seguem uma estrutura JSON padronizada:

```json
{
  "event_id": "550e8400-e29b-41d4-a716-446655440000",
  "event_type": "notification.created",
  "user_id": "user-123",
  "timestamp": "2024-01-15T10:30:00.123456Z",
  "payload": {
    "notification_title": "Nova mensagem",
    "priority": "high"
  }
}
```

#### Campos do Evento

| Campo | Tipo | DescriÃ§Ã£o | Gerado Por |
|-------|------|-----------|------------|
| `event_id` | UUID v4 | Identificador Ãºnico do evento | Sistema (auto) |
| `event_type` | string | Tipo do evento (ex: `notification.created`) | Cliente |
| `user_id` | string | ID do usuÃ¡rio relacionado | Cliente |
| `timestamp` | ISO 8601 | Data/hora UTC do evento | Sistema (auto) |
| `payload` | object | Dados especÃ­ficos do evento | Cliente |

**GeraÃ§Ã£o automÃ¡tica:**
- `event_id`: Gerado com `uuid.uuid4()` na criaÃ§Ã£o do evento
- `timestamp`: Gerado com `datetime.utcnow().isoformat()` no momento da publicaÃ§Ã£o

**Exemplo de criaÃ§Ã£o:**
```python
import uuid
from datetime import datetime

event = {
    "event_id": str(uuid.uuid4()),
    "event_type": request.event_type,
    "user_id": request.user_id,
    "payload": request.payload,
    "timestamp": datetime.utcnow().isoformat(),
}
```

### Lifespan do FastAPI

#### O que Ã© Lifespan?

O **lifespan** Ã© um context manager assÃ­ncrono do FastAPI que permite executar cÃ³digo durante o ciclo de vida da aplicaÃ§Ã£o:
- **Startup**: CÃ³digo executado quando a aplicaÃ§Ã£o inicia
- **Shutdown**: CÃ³digo executado quando a aplicaÃ§Ã£o para

#### Por que usar Lifespan?

Ã‰ a forma recomendada de gerenciar recursos que devem durar durante toda a vida da aplicaÃ§Ã£o:
- ConexÃµes com bancos de dados
- Clientes de message brokers (Kafka, RabbitMQ)
- Pools de conexÃµes
- Cache em memÃ³ria

#### ImplementaÃ§Ã£o no Projeto

```python
from contextlib import asynccontextmanager
from fastapi import FastAPI

@asynccontextmanager
async def lifespan(app: FastAPI):
    # STARTUP: Executado quando a aplicaÃ§Ã£o inicia
    await init_kafka_producer()
    logger.info("ğŸš€ Application started")
    
    yield  # A aplicaÃ§Ã£o roda aqui
    
    # SHUTDOWN: Executado quando a aplicaÃ§Ã£o para
    await close_kafka_producer()
    logger.info("ğŸ›‘ Application stopped")

app = FastAPI(
    title="Notification Producer API",
    lifespan=lifespan  # Conecta o lifespan ao app
)
```

**Fluxo de execuÃ§Ã£o:**
1. `docker-compose up` â†’ Container inicia
2. Uvicorn inicia â†’ FastAPI carrega
3. **Lifespan startup** â†’ `init_kafka_producer()` Ã© chamado
4. AplicaÃ§Ã£o fica disponÃ­vel â†’ Endpoints respondem
5. `docker-compose down` â†’ Container para
6. **Lifespan shutdown** â†’ `close_kafka_producer()` Ã© chamado

**Vantagens:**
- Garante que recursos sÃ£o liberados corretamente
- Evita memory leaks
- Permite inicializaÃ§Ã£o assÃ­ncrona de dependÃªncias
- CÃ³digo organizado e testÃ¡vel

**Alternativas (nÃ£o recomendadas):**
- âŒ `@app.on_event("startup")` e `@app.on_event("shutdown")` (deprecated)
- âŒ Inicializar no primeiro request (lento, pode falhar silenciosamente)
- âŒ Inicializar no nÃ­vel de mÃ³dulo (nÃ£o funciona com async)

---

## ğŸ”§ VariÃ¡veis de Ambiente

### notification-producer-api

| VariÃ¡vel | DescriÃ§Ã£o | Valor PadrÃ£o |
|----------|-----------|--------------|
| `KAFKA_BROKER_URL` | URL do broker Kafka | `kafka:9092` |
| `KAFKA_BOOTSTRAP_SERVERS` | Lista de servidores Kafka | `["kafka:9092"]` |
| `MONGODB_URL` | URL de conexÃ£o do MongoDB | `mongodb://root:password@mongodb:27017` |

### Kafka

| VariÃ¡vel | DescriÃ§Ã£o | Valor PadrÃ£o |
|----------|-----------|--------------|
| `KAFKA_ZOOKEEPER_CONNECT` | ConexÃ£o com Zookeeper | `zookeeper:2181` |
| `KAFKA_ADVERTISED_LISTENERS` | Listeners do Kafka | `PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093` |

### MongoDB

| VariÃ¡vel | DescriÃ§Ã£o | Valor PadrÃ£o |
|----------|-----------|--------------|
| `MONGO_INITDB_ROOT_USERNAME` | UsuÃ¡rio admin | `root` |
| `MONGO_INITDB_ROOT_PASSWORD` | Senha admin | `password` |

---

## ğŸ› ï¸ Comandos Ãšteis

### Gerenciamento de ServiÃ§os

**Parar todos os serviÃ§os:**
```bash
docker-compose down
```

**Parar e remover volumes (limpar dados):**
```bash
docker-compose down -v
```

**Reconstruir um serviÃ§o especÃ­fico:**
```bash
docker-compose up --build notification-producer-api
```

**Ver logs de um serviÃ§o especÃ­fico:**
```bash
docker-compose logs -f notification-producer-api
docker-compose logs -f kafka
docker-compose logs -f mongodb
docker-compose logs -f zookeeper
```

**Ver logs de todos os serviÃ§os:**
```bash
docker-compose logs -f
```

### Acesso aos Containers

**Acessar shell do container da API:**
```bash
docker exec -it notification-producer-api-service bash
```

**Acessar shell do Kafka:**
```bash
docker exec -it kafka bash
```

**Acessar MongoDB shell:**
```bash
docker exec -it mongodb_notification_system mongosh -u root -p password
```

### Kafka - Consumir Mensagens

**Consumir mensagens do tÃ³pico `notifications` (dentro do container Kafka):**
```bash
docker exec -it kafka bash
kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic notifications \
  --from-beginning
```

**Listar tÃ³picos:**
```bash
docker exec -it kafka bash
kafka-topics.sh --list --bootstrap-server localhost:9092
```

**Criar um tÃ³pico manualmente:**
```bash
docker exec -it kafka bash
kafka-topics.sh \
  --create \
  --bootstrap-server localhost:9092 \
  --topic notifications \
  --partitions 3 \
  --replication-factor 1
```

### MongoDB - Consultas

**Listar databases:**
```bash
docker exec -it mongodb_notification_system mongosh -u root -p password --eval "show dbs"
```

**Acessar database de notificaÃ§Ãµes:**
```bash
docker exec -it mongodb_notification_system mongosh -u root -p password notifications_db
```

---

## ğŸ—ºï¸ Roadmap

### âœ… Fase 1 - Infraestrutura Base (COMPLETO)
- [x] Setup inicial com Docker Compose
- [x] Kafka + Zookeeper configurados
- [x] MongoDB configurado
- [x] notification-producer-api com health check
- [x] ConfiguraÃ§Ã£o de logging
- [x] Gerenciamento de configuraÃ§Ãµes com Pydantic

### ğŸš§ Fase 2 - Producer API (EM ANDAMENTO)
- [x] IntegraÃ§Ã£o com Kafka Producer
- [x] ConfiguraÃ§Ã£o de settings
- [ ] Endpoint POST /events para publicar eventos
- [ ] ValidaÃ§Ã£o de payloads com Pydantic models
- [ ] GeraÃ§Ã£o automÃ¡tica de UUID para event_id
- [ ] Timestamps ISO 8601 automÃ¡ticos
- [ ] Tratamento de erros e retry

### ğŸ“‹ Fase 3 - Consumer Service (PLANEJADO)
- [ ] Criar serviÃ§o `notification-consumer`
- [ ] Consumir eventos do tÃ³pico `notifications`
- [ ] Processar e transformar eventos em notificaÃ§Ãµes
- [ ] Salvar notificaÃ§Ãµes no MongoDB
- [ ] Expor API REST para listar notificaÃ§Ãµes
- [ ] Filtros e paginaÃ§Ã£o

### ğŸ“‹ Fase 4 - Features AvanÃ§adas (FUTURO)
- [ ] Sistema de retry para eventos falhados
- [ ] Dead Letter Queue (DLQ)
- [ ] MÃ©tricas e observabilidade (Prometheus, Grafana)
- [ ] Logging estruturado (ELK Stack)
- [ ] AutenticaÃ§Ã£o e autorizaÃ§Ã£o (JWT)
- [ ] Rate limiting
- [ ] Testes unitÃ¡rios e de integraÃ§Ã£o
- [ ] CI/CD pipeline
- [ ] DocumentaÃ§Ã£o OpenAPI/Swagger completa

---

## ğŸ” Troubleshooting

### Problema: Kafka nÃ£o conecta

**Sintomas:**
- Erro: `Connection refused` ou `Bootstrap server not available`
- Logs mostram tentativas de conexÃ£o falhando

**SoluÃ§Ãµes:**
1. Aguarde ~30-60 segundos apÃ³s `docker-compose up` para o Kafka inicializar completamente
2. Verifique se o Zookeeper estÃ¡ rodando: `docker-compose ps zookeeper`
3. Verifique os logs do Kafka: `docker-compose logs kafka`
4. Certifique-se de que a variÃ¡vel `KAFKA_BROKER_URL` estÃ¡ correta

---

### Problema: notification-producer-api nÃ£o sobe

**Sintomas:**
- Container para imediatamente apÃ³s iniciar
- Erro de porta jÃ¡ em uso

**SoluÃ§Ãµes:**
1. Verifique se a porta 8001 nÃ£o estÃ¡ em uso:
   ```bash
   lsof -i :8001
   # ou
   netstat -tulpn | grep 8001
   ```
2. Verifique os logs: `docker-compose logs notification-producer-api`
3. Reconstrua a imagem: `docker-compose up --build notification-producer-api`

---

### Problema: MongoDB nÃ£o autentica

**Sintomas:**
- Erro de autenticaÃ§Ã£o ao conectar
- `Authentication failed`

**SoluÃ§Ãµes:**
1. Verifique as credenciais em `docker-compose.yaml` (padrÃ£o: `root` / `password`)
2. Se alterou as credenciais, atualize a variÃ¡vel `MONGODB_URL` no serviÃ§o da API
3. Remova o volume e recrie:
   ```bash
   docker-compose down -v
   docker-compose up -d mongodb
   ```

---

### Problema: Erro "Kafka producer nÃ£o foi inicializado"

**Sintomas:**
- RuntimeError: `Kafka producer not initialized`
- Erro ao tentar publicar evento

**SoluÃ§Ãµes:**
1. O lifespan do FastAPI gerencia a conexÃ£o automaticamente
2. Reinicie o container: `docker-compose restart notification-producer-api`
3. Verifique se o Kafka estÃ¡ acessÃ­vel: `docker-compose logs kafka`
4. Verifique a conectividade de rede: `docker network inspect notification-producer-api_notification-network`

---

### Problema: TÃ³pico Kafka nÃ£o existe

**Sintomas:**
- Erro ao publicar: `Topic not found`

**SoluÃ§Ãµes:**
1. O tÃ³pico serÃ¡ criado automaticamente na primeira publicaÃ§Ã£o (se `auto.create.topics.enable=true`)
2. Crie manualmente (veja seÃ§Ã£o [Comandos Ãšteis](#-comandos-Ãºteis))
3. Verifique a configuraÃ§Ã£o do Kafka em `docker-compose.yaml`

---

### Problema: DependÃªncias nÃ£o instalam

**Sintomas:**
- Erro durante `docker-compose build`
- `uv sync` falha

**SoluÃ§Ãµes:**
1. Verifique se o `uv.lock` estÃ¡ atualizado
2. Limpe o cache do Docker: `docker system prune -a`
3. Reconstrua sem cache: `docker-compose build --no-cache`

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. **Fork** o projeto
2. Crie uma **branch** para sua feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. **Push** para a branch (`git push origin feature/AmazingFeature`)
5. Abra um **Pull Request**

### Guidelines

- Siga os padrÃµes de cÃ³digo existentes
- Adicione testes para novas funcionalidades
- Atualize a documentaÃ§Ã£o quando necessÃ¡rio
- Use commits descritivos e em portuguÃªs

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ğŸ‘¥ Contato / Maintainers

- **Willames Campos** - [willwjccampos@gmail.com](mailto:willwjccampos@gmail.com)

---

## ğŸ™ Agradecimentos

- [FastAPI](https://fastapi.tiangolo.com/) - Framework web moderno
- [Apache Kafka](https://kafka.apache.org/) - Message broker distribuÃ­do
- [Confluent](https://www.confluent.io/) - Plataforma Kafka
- [uv](https://github.com/astral-sh/uv) - Gerenciador de pacotes Python

---

<div align="center">

**â­ Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela! â­**

</div>
